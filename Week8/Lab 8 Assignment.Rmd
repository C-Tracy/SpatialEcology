---
title: "R Notebook"
output: html_notebook
---

```{r}
#Don't forget to load your R packages!
require(tidyterra)
require(dismo)
require(tidyverse)
require(terra)
require(predicts)
require(ggnewscale)
require(mgcv)
require(randomForest)
require(maxnet)
require(enmSdmX)
require(gbm)
require(landscapemetrics)


# Read in data

vathData = read.csv('https://raw.githubusercontent.com/ValenteJJ/SpatialEcology/main/Week8/vath_2004.csv')

vathPres = vathData %>% filter(VATH==1)
vathAbs = vathData %>% filter(VATH==0)

vathPresXy = as.matrix(vathPres %>% select(EASTING, NORTHING))
vathAbsXy = as.matrix(vathAbs %>% select(EASTING, NORTHING))


vathVal = read.csv('https://raw.githubusercontent.com/ValenteJJ/SpatialEcology/main/Week8/vath_VALIDATION.csv')

vathValPres = vathVal %>% filter(VATH==1)
vathValAbs = vathVal %>% filter(VATH==0)

vathValXy = as.matrix(vathVal %>% select(EASTING, NORTHING))
vathValPresXy = as.matrix(vathValPres %>% select(EASTING, NORTHING))
vathValAbsXy = as.matrix(vathValAbs %>% select(EASTING, NORTHING))


elev = rast('https://github.com/ValenteJJ/SpatialEcology/raw/main/Week8/elevation.tif')
canopy = rast('https://github.com/ValenteJJ/SpatialEcology/raw/main/Week8/canopy.tif')
mesic = rast('https://github.com/ValenteJJ/SpatialEcology/raw/main/Week8/mesic.tif')
precip = rast('https://github.com/ValenteJJ/SpatialEcology/raw/main/Week8/precip.tif')

crs(elev) = crs(mesic)
crs(canopy) = crs(mesic)

mesic = resample(x = mesic, y = elev, 'near')
precip = resample(x = precip, y = elev, 'bilinear')

mesic = mask(mesic, elev)
precip = mask(precip, elev)

probMatrix = focalMat(mesic, 1000, type='circle', fillNA=FALSE)
mesic1km = focal(mesic, probMatrix, fun='sum')

layers = c(canopy, elev, mesic1km, precip)
names(layers) = c('canopy', 'elev', 'mesic1km', 'precip')
```



# Challenge 1 (4 points)

In the lab, we created 6 species distribution models (SDMs) for the same species using 6 different techniques. Plot the maps generated from (1) the bioclim envelope function, (2) the GLM model, and (3) the random forest model next to one another. What similarities and differences do you notice among these maps? What might explain some of these differences?

```{r}
#Place code here

#background points
set.seed(23)

backXy = data.frame(backgroundSample(layers, n=2000, p=vathPresXy))

#pulling out data

presCovs = extract(layers, vathPresXy)
backCovs = extract(layers, backXy)
valCovs = extract(layers, vathValXy)

presCovs = data.frame(vathPresXy, presCovs, pres=1)
backCovs = data.frame(backXy, backCovs, pres=0)
valCovs = data.frame(vathValXy, valCovs)

presCovs = presCovs[complete.cases(presCovs),]
backCovs = backCovs[complete.cases(backCovs),]
valCovs = valCovs[complete.cases(valCovs),]


backCovs = backCovs %>% select(-ID)
colnames(presCovs)[1:2] = c('x', 'y')

presBackCovs = rbind(presCovs, backCovs)


#bioclim envelope function

tmp = presCovs %>% select(elev, precip, mesic1km, canopy) %>% 
  as.matrix()

bioclim = envelope(tmp)


plot(bioclim, a=1, b=2, p=0.95)
plot(bioclim, a=1, b=3, p=0.95)
plot(bioclim, a=3, b=4, p=0.95)

bioclimMap = predict(layers, bioclim)
plot(bioclimMap)

#GLM model
glmModel = glm(pres ~ canopy + elev + I(elev^2) + mesic1km + precip, family='binomial', data=presBackCovs)

summary(glmModel)

glmMap = predict(layers, glmModel, type='response')
plot(glmMap)

#random forest model
tuneRF(y = as.factor(presBackCovs$pres), x=presBackCovs[,3:6], stepFactor = 2, ntreeTry = 500)
rfModel = randomForest(as.factor(pres) ~ canopy + elev + mesic1km + precip, data=presBackCovs, mtry=2, ntree=500, na.action = na.omit)

rfMap = predict(layers, rfModel, type='prob', index=2)
plot(rfMap)

# Plot all three next to each other
par(mfrow = c(1,3)) 
plot(bioclimMap, main="bioclim")
plot(glmMap, main="glm")
plot(rfMap, main="rf")

```
Q: What similarities and differences do you notice among these maps? What might explain some of these differences?

The bioclim and the rf models both estimate much higher values of likelihood of encountering the species in the habitat. 
In addition the bioclim model estimates a larger area of space on the map with higher likelihoods.
Given the different scales that result it is a little difficult to compare the results, but overall it seems that they all have similar trends where the more likely areas that would be occupied are in the same area, but the values of that probability vary across models. 
One difference in trends across the landscape is that the bioclim and glm models show stronger trends with the environment, and particularly you can see that the species has a higher liklihood from both models as you move closer to a river, and thus you can more clearly see rivers in those two maps (with an estimate of 0 chance of encountering the species). 
That fine-scale structure isn't seen in the rf model. 
The small scale of the bioclim map could be a result of being analysed from presence-only data, and not incorporating background absences, and from all covariates provided being included in the model with equal weight (an inevitable process in the bioclim analysis).
The glm being quite low estimates may be a result of the number of background points included. This might also drive the low amount of areas with high likelihood in the rf model as well. I anticipate that it would appear more similar to the glm map if the colors were on the same scale for likelihood values. 

$\color{red}{\text{Great. +4}}$


# Challenge 2 (4 points)

When we fit our GLM in lab, we used background points, rather than true absence points, to represent pseudo-absences. Fit the exact same GLM model, only this time use presence and true absence data. That is, replace the background rows in the dataframe with rows that represent actual sites where surveys were completed but Varied Thrush were not detected. Once you've fit the GLM, build a new SDM from this fitted model and visually compare the prediction surface to that built based on the presence-background model. What discrepancies do you notice, and what is your intuition regarding which of these two models is more reliable?

```{r}
#Place code here
#Formatting absence

#presCovs = extract(layers, vathPresXy)
absCovs = extract(layers, vathAbsXy)
#valCovs = extract(layers, vathValXy)

#presCovs = data.frame(vathPresXy, presCovs, pres=1)
absCovs = data.frame(vathAbsXy, absCovs, pres=0)
#valCovs = data.frame(vathValXy, valCovs)

#presCovs = presCovs[complete.cases(presCovs),]
absCovs = absCovs[complete.cases(absCovs),]
#valCovs = valCovs[complete.cases(valCovs),]

colnames(presCovs)[1:2] = c('x', 'y')
colnames(absCovs)[1:2] = c('x', 'y')
presAbsCovs = rbind(presCovs, absCovs)

#New GLM with true absence data

glmModel_presabs = glm(pres ~ canopy + elev + I(elev^2) + mesic1km + precip, family='binomial', data=presAbsCovs)

summary(glmModel_presabs)

glmMap_presabs = predict(layers, glmModel_presabs, type='response')
plot(glmMap_presabs)

#Compare
par(mfrow = c(1,2)) 
plot(glmMap, main="glm background")
plot(glmMap_presabs, main="glm true absence")


```
What discrepancies do you notice, and what is your intuition regarding which of these two models is more reliable?

When using true absence data in creating our model we get a similar map with the same structure, but we get much higher values (.8 rather than .3 seen with background) and we also see larger areas of land in those areas of high probability with the true absence rather than background estimates. 
There also appear to be larger areas of significantly lower likelihood with the true absence, which to me indicates that we get better estimates, and can better differentiate these likelihoods when using true absences. 
That being said, the maps really do look VERY similar, and to me this also demonstrates that using background data can get you very close to the same answer and true absences, and is a good workaround, especially as I anticipate datasets with true absences are less common to find. 
Finally, this difference in likelihood estimates is probably from the number of background points used. Were we to estimate fewer background points, and have less of a signal from those background absences, these likelihood estimates would be higher. 

$\color{red}{\text{Great. +4}}$


# Challenge 3 (4 points)

Now plot the relationship between the 4 explanatory variables and the predicted occupancy values based on the two fitted GLM models (presence-background and presence-absence). Recall that we did this in the latter part of our lab. Do you notice any differences in the covariate patterns between the two models? Does this help you interpret the discrepancies between the predicted surfaces from the two models?

```{r}
#Place code here

tmp = expand.grid(elev = seq(min(backCovs$elev), max(backCovs$elev), length=1000),
                  canopy = mean(backCovs$canopy),
                  precip = mean(backCovs$precip),
                  mesic1km = mean(backCovs$mesic1km))


elevData = data.frame(glm_bg = predict(glmModel, tmp, type='response'), 
                      glm_abs = predict(glmModel_presabs, tmp, type='response')) %>%
  cbind(tmp) %>% 
  select(glm_bg:glm_abs, elev) %>% 
  pivot_longer(glm_bg:glm_abs) %>% 
  mutate(variable = 'elevation')

tmp = expand.grid(elev = mean(backCovs$elev),
                  canopy = seq(min(backCovs$canopy), max(backCovs$elev), length=1000),
                  precip = mean(backCovs$precip),
                  mesic1km = mean(backCovs$mesic1km))

canopyData = data.frame(glm_bg = predict(glmModel, tmp, type='response'), 
                      glm_abs = predict(glmModel_presabs, tmp, type='response')) %>% 
  cbind(tmp) %>% 
  select(glm_bg:glm_abs, canopy) %>% 
  pivot_longer(glm_bg:glm_abs) %>% 
  mutate(variable = 'canopy')

tmp = expand.grid(elev = mean(backCovs$elev),
                  canopy = mean(backCovs$canopy),
                  precip = seq(min(backCovs$precip), max(backCovs$precip), length=1000),
                  mesic1km = mean(backCovs$mesic1km))

precipData = data.frame(glm_bg = predict(glmModel, tmp, type='response'), 
                      glm_abs = predict(glmModel_presabs, tmp, type='response')) %>% 
  cbind(tmp) %>% 
  select(glm_bg:glm_abs, precip) %>% 
  pivot_longer(glm_bg:glm_abs) %>% 
  mutate(variable = 'precipitation')

tmp = expand.grid(elev = mean(backCovs$elev),
                  canopy = mean(backCovs$canopy),
                  precip = mean(backCovs$precip),
                  mesic1km = seq(min(backCovs$mesic1km), max(backCovs$mesic1km), length=1000))

mesicData = data.frame(glm_bg = predict(glmModel, tmp, type='response'), 
                      glm_abs = predict(glmModel_presabs, tmp, type='response')) %>% 
  cbind(tmp) %>% 
  select(glm_bg:glm_abs, mesic1km) %>% 
  pivot_longer(glm_bg:glm_abs) %>% 
  mutate(variable = 'mesic1km')


colnames(elevData)[1] = colnames(canopyData)[1] = colnames(precipData)[1] = colnames(mesicData)[1] = 'xValue'

tmp = rbind(elevData, canopyData, precipData, mesicData)

ggplot(tmp, aes(x=xValue, y=value, color=name))+
  facet_wrap(~variable, scales='free_x')+
  geom_line()+
  theme_bw()+
  theme(panel.grid=element_blank())

```
Do you notice any differences in the covariate patterns between the two models? Does this help you interpret the discrepancies between the predicted surfaces from the two models?

There is a difference in the covariate pattern between absence and background with precipitation. The likelihood of occupancies are in general much higher with precipitation for the true absence model compared to the background model, but this could again be a result of the number of background points used in the model. 
To me this difference in shape may be a result of a higher accuracy in the model from using true absence data, such that you see it plateau earlier in the abs than bg model. But overall they all look very similar to me, and indicate that this background method does a good job at estimating absence data.  

$\color{red}{\text{Nice. +4}}$


# Challenge 4 (4 points)

Varied Thrush are considered forest-dependent, and thus one might characterize mesic forests as "habitat" for the species. Calculate the total amount of mesic forest in the study area, and the mean size of the mesic forest patches.

Using the SDM built from the random forest model, convert the landscape into "habitat" and "non-habitat." To do this, choose a threshold value in your SDM and convert all cells with predicted outcomes greater than this threshold to 1 and all cells with predicted values below your threshold to 0. Justify your choice of your threshold value. Now calculate the total amount of habitat and mean size of habitat patches based on this new raster (i.e., create patches of "habitat" based on aggregations of cells you deemed 1). How do the habitat amount and patch size values compare between the mesic forest approach and the SDM-based approach? In what situations might you rely on one map over the other?

```{r}
#Place code here

#Total amount of mesic forest in study area
lsm_c_ca(mesic, directions=8)
##0 = 6,901,764 (non-mesic)
##1 = 4,021,700 (mesic)
#total area = 

#Mean size of mesic forest patches
lsm_c_area_mn(mesic, directions=8)
#0=806.0925
#1=749.0594

#Bringing in code from random forest model
tuneRF(y = as.factor(presBackCovs$pres), x=presBackCovs[,3:6], stepFactor = 2, ntreeTry = 500)

rfModel = randomForest(as.factor(pres) ~ canopy + elev + mesic1km + precip, data=presBackCovs, mtry=2, ntree=500, na.action = na.omit)

rfMap = predict(layers, rfModel, type='prob', index=2)
plot(rfMap)

#Subsetting into habitat and non-habitat from rf model

#code from Jonathan that works
habitat = rfMap
habitat[habitat <= 0.4] = 0
habitat[habitat > 0.4] = 1

#total amount of habitat type in lanscape
lsm_c_ca(habitat, directions=8)
#0=10,670,044
#1=75,264

#mean size of habitat patches
lsm_c_area_mn(habitat, directions=8) #mean of patch area
#0=463,914.95652
#1=13.20189



```
1). How do the habitat amount and patch size values compare between the mesic forest approach and the SDM-based approach? In what situations might you rely on one map over the other?

In the mesic forest approach, the total amount of mesic forest "habitat" is 4,021,700, while in the SDM cut-off approach the total amount of "habitat is 75,264 with a cutoff likelihood value of 0.4. 

In the mesic forest approach, the total amount of non-mesic forest "non-habitat" is 6,901,764, while in the SDM approach the total amount of "non-habitat is 10,670,044. 

Overall, the mesic forest estimates a much higher amount of mesic forest habitat than the SDM cutoff approach. I would be inclined to use the SDM approach, but only after the models seem fully validated. The mesic forest approach to me relies a lot on a generalization of the habitat type of a species, however doesn't take into account all of the other possible variables that influence species distributions. However, I think it is also important to use ecological knowledge to inform our models. 

$\color{red}{\text{What about patch size and a justification for your cutoff value? +3}}$


# Challenge 5 (4 points)

When we fit the Maxent model in the lab, we used a regularization constant of 1. Fit the model two more times, using regularization (regmult) constants of 0.5 and 3. Construct figures showing the relationship between the 4 explanatory variables and the predicted outcome from these 3 fitted Maxent models. What is the regularization constant doing? Hint: you may need to Google it.

```{r}
#Place code here

#maxent model from lab

pbVect = presBackCovs$pres
covs = presBackCovs %>% select(canopy:precip)

maxentModel_1 = maxnet(p = pbVect,
                     data= covs,
                     regmult = 1,
                     classes='lqpht')

plot(maxentModel_1, type='logistic')

maxentMap_1 = predictMaxNet(maxentModel_1, layers, type='logistic')

maxentModel_3 = maxnet(p = pbVect,
                     data= covs,
                     regmult = 3,
                     classes='lqpht')

plot(maxentModel_3, type='logistic')

maxentMap_3 = predictMaxNet(maxentModel_3, layers, type='logistic')

maxentModel_0.5 = maxnet(p = pbVect,
                     data= covs,
                     regmult = 0.5,
                     classes='lqpht')

plot(maxentModel_0.5, type='logistic')

maxentMap_0.5 = predictMaxNet(maxentModel_1, layers, type='logistic')

par(mfrow=c(1,3))
plot(maxentMap_0.5, main="reg. const. = 0.5")
plot(maxentMap_1, main="reg. const. = 1")
plot(maxentMap_3, main="reg. const. = 3")


## Relationship between explanatory variables and predicted outcomes

tmp = expand.grid(elev = seq(min(backCovs$elev), max(backCovs$elev), length=1000),
                  canopy = mean(backCovs$canopy),
                  precip = mean(backCovs$precip),
                  mesic1km = mean(backCovs$mesic1km))


elevData = data.frame(maxent1 = predict(maxentModel_1, tmp, type='logistic'), 
                      maxent0.5 = predict(maxentModel_0.5, tmp, type='logistic'), 
                      maxent3 = predict(maxentModel_3, tmp, type='logistic')) %>%
  cbind(tmp) %>% 
  select(maxent1:maxent3, elev) %>% 
  pivot_longer(maxent1:maxent3) %>% 
  mutate(variable = 'elevation')

tmp = expand.grid(elev = mean(backCovs$elev),
                  canopy = seq(min(backCovs$canopy), max(backCovs$elev), length=1000),
                  precip = mean(backCovs$precip),
                  mesic1km = mean(backCovs$mesic1km))

canopyData = data.frame(maxent1 = predict(maxentModel_1, tmp, type='logistic'), 
                      maxent0.5 = predict(maxentModel_0.5, tmp, type='logistic'), 
                      maxent3 = predict(maxentModel_3, tmp, type='logistic')) %>%
  cbind(tmp) %>% 
  select(maxent1:maxent3, canopy) %>% 
  pivot_longer(maxent1:maxent3) %>% 
  mutate(variable = 'canopy')

tmp = expand.grid(elev = mean(backCovs$elev),
                  canopy = mean(backCovs$canopy),
                  precip = seq(min(backCovs$precip), max(backCovs$precip), length=1000),
                  mesic1km = mean(backCovs$mesic1km))

precipData = data.frame(maxent1 = predict(maxentModel_1, tmp, type='logistic'), 
                      maxent0.5 = predict(maxentModel_0.5, tmp, type='logistic'), 
                      maxent3 = predict(maxentModel_3, tmp, type='logistic')) %>%
  cbind(tmp) %>% 
  select(maxent1:maxent3, precip) %>% 
  pivot_longer(maxent1:maxent3) %>% 
  mutate(variable = 'precipitation')

tmp = expand.grid(elev = mean(backCovs$elev),
                  canopy = mean(backCovs$canopy),
                  precip = mean(backCovs$precip),
                  mesic1km = seq(min(backCovs$mesic1km), max(backCovs$mesic1km), length=1000))

mesicData = data.frame(maxent1 = predict(maxentModel_1, tmp, type='logistic'), 
                      maxent0.5 = predict(maxentModel_0.5, tmp, type='logistic'), 
                      maxent3 = predict(maxentModel_3, tmp, type='logistic')) %>%
  cbind(tmp) %>% 
  select(maxent1:maxent3, mesic1km) %>% 
  pivot_longer(maxent1:maxent3) %>% 
  mutate(variable = 'mesic1km')


colnames(elevData)[1] = colnames(canopyData)[1] = colnames(precipData)[1] = colnames(mesicData)[1] = 'xValue'

tmp = rbind(elevData, canopyData, precipData, mesicData)

ggplot(tmp, aes(x=xValue, y=value, color=name))+
  facet_wrap(~variable, scales='free_x')+
  geom_line()+
  theme_bw()+
  theme(panel.grid=element_blank())

```
Construct figures showing the relationship between the 4 explanatory variables and the predicted outcome from these 3 fitted Maxent models. What is the regularization constant doing?

A smaller value of regularization multiplier makes the model more localized, and a larger value will make more generalized and more spread out. The smaller means it closer to the training data, but can thus be overfit, whereas larger provide a penalty for model complexity and will minimize the chances of overfitting.
From these figures of explanatory variables and predicted outcomes, the largest difference stands out in precipitation again, with the lower reg. const. producing a dropoff after 100, whereas the models for 1 and 3 continue to increase in predictive value. 
To me this is an indication that the 0.5 value might cause overfitting, and that is what is changing the shape of the curve in the relationship with precipitation and the estimated likelihood of occupancy. 

$\color{red}{\text{Awesome. +4}}$
